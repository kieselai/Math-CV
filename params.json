{
  "name": "Math-CV (Math Computer Vision)",
  "tagline": "Handwriting Recognition, Math solver",
  "body": "### Introduction\r\nOne of the amazing things about artificial intelligence, is the ability of a computer to recognize and complete things that are tedious, error prone, or difficult for people to do. Math is the subject that often falls into all three of these situations. Even experts mathematicians commonly make simple mistakes that could potentially be found in real time given an intelligent system with nearly instantaneous solutions. This is where the main focus of this project comes into play. \r\n\r\n___\r\n\r\n### Description\r\nMath-CV is my solution to help make math education more effective and to assist workers in math-heavy professions in solving problems in their day to day lives.  The overall vision of Math-CV is that a user can submit an image to the Math-CV software, and the software will return an interpretation of the submitted image.  This interpretation could simply be a listing of all equations found in the submission image, but it can also be solutions, or even step-by-step solutions to the equations found. In it's current state, Math-CV will return the submitted equation in addition to a solution if one can be found. Results are currently limited to a very small subset of the eventual solution, namely numbers and the following operators: \"+-*/\".  \r\n\r\n___\r\n\r\n### How does it work?\r\nThe overall process that Math-CV goes through is outlined as follows:\r\n1. A handwritten input image is submitted to the Math-CV software. \r\n2. The program identifies what symbols, characters, and numbers are written in the submitted image. \r\n3. The program organizes identified symbols into a logical order based on their relative position in the image.\r\n4. The program can now utilize the information collected from the image. This may include returning the solution, returning steps to a solution, and returning the equation that was identified.\r\n\r\n___\r\n\r\n### Methods and Technologies\r\nMath-CV utilizes a support vector machine to identify images. Training the SVM involves mapping a matrix containing each training image and its features vector, to a vector of identifying labels. Before any features are determined to identify an image, the image is de-skewed.  If an character is written with a tilt, this will correct the orientation of the image allowing comparisons between images of the same type to be more accurate.  \r\n\r\nAfter correcting the orientation of each image, each image must be resized to be the same size.  In this case, I used 64x64 sized images.  First images were cropped to get rid of any white background.  Following this, images needed to be size to 64x64; however, most images will not scale perfectly to a square size. To correct this, an image is resized until either the width or height is exactly 64 pixels, and the other dimension is simply padded with white background equally from top and bottom or left and right so that the image is centered. \r\n\r\nSome images in image recognition will require far more processing than what has been described in order to filter out qualities of the image that are present due to bad image quality or due to the conditions the image was taken in.  In that case blurs, filters, and thresholding are often needed. In this case, images are produced digitally, and there is very little issue with image quality, so for our training set none of this is done.\r\n\r\nAt this point, HOG (Histogram of Gradients) is the method that I used to map an image to a feature set.  The HOG is a histogram identifying the frequency that specific magnitudes and directions are found in an image. This turns out to be a pretty accurate way of determining what the image contains. This maps to a flattened vector, that can then describe this single image.\r\n\r\nFollowing pre-processing of training data, the SVM machine is trained with the training images.  I'm still not certain why, but original training of the SVM machine often took over an hour.  At some point, training data was reduced, changed, and HOG employed, which seems to have cut training time down to around 20 seconds.  \r\n\r\nFor submitting training data, I wanted the process to be very open and easy to access.  I wanted the software to be usable not only where it is installed, but also via a web API.  The current implementation is reliant solely on the web application front-end, however a few small changes would allow the software to be accessible through an open API that allows a user to submit an image, and receive JSON results.\r\n\r\nThe application front-end provides a simple drawing interface, with the ability to submit an image, and results posted below.  Once an image is submitted, it must go through pre-processing steps unique to submitted images.  This is due to the fact that images submitted together must be separated from each other in order to determine symbol identification apart from one another.  The overall idea is to find connected pieces and consider this a distinct symbol.  This wouldn't work in the case of sloppy handwriting, but in most cases works just fine.  \r\n\r\nFirst the image needs to have a blur and dilation applied to make sure that lines that are very close together are connected.  This is an issue that was needed due to lines drawn on the application canvas having very small fragmentation between them that cause the application to process the images into multiple pieces. This might also be an issue with images submitted from a camera or scanned image.  In any case, we want to treat paths that are very very close together as the same path.  \r\n\r\nOnce pre-processing is completed on the full image, the image is separated into individual symbols that are cropped and organized by the left-most x-coordinate of the symbol. Following the separation of each character, each image is then sent through the same deskew and resize pre-processing as the training data before finally having HOG features calculated for the submitted characters.\r\n\r\nAt this point, the only thing that needs to be done is prediction from the trained SVM machine.  In the case of the web-application, a node-js application communicates through a TCP connection with my python app that responds with the needed predictions, before finally returning JSON results to the web page.  \r\n___\r\n![10-Fold Cross Validation](https://drive.google.com/file/d/0Bx5ToeN08zKxdUFMTV9MVzVWRVk/view?usp=sharing)\r\n### Results\r\n\r\nUsing training data as the basis for results, Math-CV has a near perfect classification rate of around 98-99%.  Overall the application is mostly correct in classifying symbols and returning the correct solution provided that very neat handwriting is used and that digits are written in the specific way that I trained them.  Symbols are trained with the following constraints:\r\n    Ones are simply a straight line\r\n    Fours do not have a point at the top, but are instead draw straight up.\r\n    Nines do not have a curved tail at the bottom, but are instead drawn straight down.\r\n    Multiplication is drawn as an asterisk.\r\n    Division is drawn as a forward slash.\r\n\r\n### Future Problems to Solve\r\nIn practice, there are issues that I had not accounted for that need further thought and consideration.  First, I picked only training images that were very well drawn.  This was a result of having encountered abysmally low classification rates with the original training data.  As a result of receiving these bad results, myself and others I recruited spent many hours creating training data to add to the original set that I had reduced to much smaller numbers.  I think this was ultimately a good thing in terms of quality control; however, the predictions of the classifier may have become somewhat biased towards my own handwriting as a result of the tight control on training data. Math-CV might benefit from individualized training data, but ultimately would benefit most from having multiple choices in how symbols may be drawn and aggregated training samples from many different sources, potentially with further considerations in how features are chosen.\r\n\r\nHOG features were overall a very good fit for what has been accomplished so far.  There are however a few issues with the use of HOG features.  I was initially unaware of any issues with using HOG for my feature set since the training data allowed the classifier to classify other training data with near perfect results.  The issue is that this was all created by drawing with my finger on a touch screen; however, attempting to write on the html canvas using a mouse instead leads to handwriting that is sloppier and much harder to classify.  The main issue I have started to see, is that HOG features are heavily biased towards the magnitudes of vectors.  Research into the topic confirms what I have seen myself.  In fact, it seems fairly well known in image processing that this is a potential problem.  Some solutions have been proposed to truncate magnitudes or to normalize them in order to make HOG less biased towards magnitudes, and classify based more on directions and existence of vectors.\r\n\r\nAn example of this issue can be seen by drawing a 4 with a very long vertical portion.  The classifier classifies this symbol as a 4 if the vertical portion is much shorter; however, a four drawn with an exaggerated vertical portion often results in classification as a 1. In other cases, A 2 with a very long bottom horizontal line would result in classification as a 5. \r\n\r\nAnother common issue is that the classifier will predict that anything containing a lot of sloppy lines as an asterisk or a plus sign.  If for example, a bunch of scribbles were drawn, it often classifies this as an asterisk.  The issue is that this doesn't only apply towards scribbles, but also sloppy writing.  Of course, there can always be the requirement that neat handwriting is used to fully utilize the application, but many of these characters are easily classified by a person, so there really must be a better way.  \r\n\r\nIn addition to tuning accuracy of predictions, Math-CV can benefit from addition of further capabilities. By checking for the original relative size and position of a character relative to another, it would be possible to add support for things like exponents and subscripts.  If the application were to check for a vertical line running underneath a symbol or equation, followed by another symbol or equation below the line, it would be possible for Math-CV to support calculating fractions using notation that is more friendly than a forward slash.  Adding support for letter variables, parenthesis, derivatives, summations, integrals and other common math equations are also possible through added training samples and the addition of a computer algebra system.\r\n\r\n___\r\n\r\n### Demo\r\nA current implementation of Math-CV is available at the following address:\r\nhttps://math-cv.disaster.space/\r\n\r\n___\r\n\r\n### Author\r\nAnthony Kiesel ([@kieselai](https://github.com/kieselai))\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}